{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "772bc205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2 as cv\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "leo_image = face_recognition.load_image_file(\"photos/leo.jpg\")\n",
    "bea_image = face_recognition.load_image_file(\"photos/bea.jpg\")\n",
    "\n",
    "try:\n",
    "    bea_face_encoding = face_recognition.face_encodings(bea_image)[0]\n",
    "    leo_face_encoding = face_recognition.face_encodings(leo_image)[0]\n",
    "except Error:\n",
    "    print(\"I didn't find any faces, quitting...\\n\")\n",
    "    time.sleep(0.02)\n",
    "    print(\".\\n\")\n",
    "    time.sleep(0.02)\n",
    "    print(\".\\n\")\n",
    "    time.sleep(0.02)\n",
    "    print(\".\\n\")\n",
    "    \n",
    "    \n",
    "# Create arrays of known face encodings and their names\n",
    "known_face_encodings = [\n",
    "    leo_face_encoding,\n",
    "    bea_face_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Leo\",\n",
    "    \"Bea\"\n",
    "]\n",
    "ochiolino = False\n",
    "sorriso = False\n",
    "sblocco = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f930aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "[(242, 464, 464, 241)]\n",
      "[{'chin': [(221, 317), (226, 349), (233, 379), (241, 407), (256, 433), (275, 455), (301, 469), (331, 476), (363, 476), (390, 471), (409, 458), (421, 436), (428, 410), (433, 385), (435, 360), (436, 335), (434, 309)], 'left_eyebrow': [(250, 288), (266, 269), (291, 261), (318, 261), (342, 269)], 'right_eyebrow': [(363, 270), (381, 262), (402, 261), (420, 266), (430, 283)], 'nose_bridge': [(357, 292), (361, 309), (365, 326), (369, 344)], 'nose_tip': [(338, 365), (351, 368), (364, 370), (375, 367), (384, 363)], 'left_eye': [(280, 305), (291, 298), (305, 295), (318, 301), (306, 306), (293, 307)], 'right_eye': [(379, 299), (391, 293), (403, 294), (413, 301), (403, 304), (391, 303)], 'top_lip': [(315, 416), (334, 405), (351, 399), (363, 401), (373, 398), (385, 403), (395, 412), (389, 411), (373, 407), (363, 408), (351, 408), (323, 415)], 'bottom_lip': [(395, 412), (385, 418), (374, 419), (363, 420), (352, 421), (335, 421), (315, 416), (323, 415), (352, 409), (362, 409), (373, 407), (389, 411)]}]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "capture = cv.VideoCapture(0)\n",
    "  \n",
    "while(True):\n",
    "    ochiolino = False\n",
    "    sblocco = False\n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    apertura_sx = 0\n",
    "    apertura_dx = 0\n",
    "    ret, frame = capture.read()\n",
    "    rgb_frame = frame[:, :, ::-1]  \n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "    \n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        # See if the face is a match for the known face(s)\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        # If a match was found in known_face_encodings, just use the first one.\n",
    "        # if True in matches:\n",
    "        #     first_match_index = matches.index(True)\n",
    "        #     name = known_face_names[first_match_index]\n",
    "\n",
    "        # Or instead, use the known face with the smallest distance to the new face\n",
    "        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        if matches[best_match_index]:\n",
    "            name = known_face_names[best_match_index]\n",
    "            sblocco = True\n",
    "        else:\n",
    "            sblocco = False\n",
    "        # Draw a box around the face\n",
    "        cv.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv.FILLED)\n",
    "        font = cv.FONT_HERSHEY_DUPLEX\n",
    "        cv.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('frame', frame)\n",
    "    if sblocco:\n",
    "        face_landmarks_list = face_recognition.face_landmarks(frame)\n",
    "        if face_landmarks_list:\n",
    "            apertura_sx = abs(face_landmarks_list[0][\"left_eye\"][4][1] - face_landmarks_list[0][\"left_eye\"][2][1])\n",
    "            apertura_dx = abs(face_landmarks_list[0][\"right_eye\"][4][1] - face_landmarks_list[0][\"right_eye\"][2][1])\n",
    "        pil_image = Image.fromarray(rgb_frame)\n",
    "        toll1 = pil_image.size[1]//40\n",
    "        toll2 = pil_image.size[1]//41\n",
    "        if apertura_sx+apertura_dx<5:\n",
    "            print(\"troppo lontano\")\n",
    "        else:\n",
    "            if apertura_dx <= toll2 or apertura_sx <= toll2:\n",
    "                ochiolino = True\n",
    "            else:\n",
    "                if apertura_dx <= toll1 or apertura_sx <= toll1:\n",
    "                    ochiolino = True\n",
    "                else:\n",
    "                    print(\"nessun occhio chiuso\")\n",
    "    if cv.waitKey(1) & 0xFF == ord('q') or ochiolino:\n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object\n",
    "capture.release()\n",
    "# Destroy all the windows\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "print(apertura_dx)\n",
    "print(apertura_sx)\n",
    "print(face_locations)\n",
    "print(face_landmarks_list)\n",
    "print(ochiolino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8020c8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "11\n",
      "640\n",
      "480\n"
     ]
    }
   ],
   "source": [
    "print(toll1)\n",
    "print(toll2)\n",
    "print(pil_image.size[0])\n",
    "print(pil_image.size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2966bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118, 216, 341, 0)\n",
      "(400, 250, 3)\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "imagen = face_recognition.load_image_file(\"photos/leo.jpg\")\n",
    "small_frame = cv2.resize(imagen, (250, 400))\n",
    "face_locations = face_recognition.face_locations(small_frame)\n",
    "\n",
    "images = face_recognition.load_image_file(\"photos/not_smile.jpg\")\n",
    "face_landmarks_list = face_recognition.face_landmarks(imagen)\n",
    "image = Image.fromarray(small_frame)\n",
    "\n",
    "\n",
    "\n",
    "print(face_locations[0])\n",
    "top, right, bottom, left = face_locations[0]\n",
    "print(small_frame.shape)\n",
    "cv2.imshow(\"frame\", small_frame)\n",
    "cv2.imshow(\"cframe\", small_frame[top:bottom, left:right])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e17f4ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[(708, 2373), (852, 2320), (1014, 2306), (1163, 2360), (1023, 2402), (859, 2417)]\n",
      "96\n",
      "\n",
      "\n",
      "[(1864, 2355), (2009, 2297), (2166, 2324), (2284, 2393), (2160, 2422), (2016, 2405)]\n",
      "98\n",
      "\n",
      "\n",
      "[(2008, 3704), (1854, 3803), (1687, 3829), (1532, 3845), (1393, 3835), (1206, 3802), (1014, 3719), (1105, 3721), (1398, 3657), (1531, 3666), (1679, 3661), (1930, 3708)]\n",
      "\n",
      "\n",
      "132 128\n",
      "qualche occhio chiuso\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-c2l3r8zm\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18832/2153751389.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_landmarks_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bottom_lip'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m110\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"frame\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmall_frame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-c2l3r8zm\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2 as cv\n",
    "from PIL import Image, ImageDraw\n",
    "import time\n",
    "\n",
    "imagen = face_recognition.load_image_file(\"photos/leo.jpg\")\n",
    "print(\"\\n\")\n",
    "print(face_landmarks_list[0][\"left_eye\"])\n",
    "apertura_sx = abs(face_landmarks_list[0][\"left_eye\"][4][1] - face_landmarks_list[0][\"left_eye\"][2][1])\n",
    "print(apertura_sx)\n",
    "print(\"\\n\")\n",
    "print(face_landmarks_list[0][\"right_eye\"])\n",
    "apertura_dx = abs(face_landmarks_list[0][\"right_eye\"][4][1] - face_landmarks_list[0][\"right_eye\"][2][1])\n",
    "print(apertura_dx)\n",
    "print(\"\\n\")\n",
    "print(face_landmarks_list[0]['bottom_lip'])\n",
    "print(\"\\n\")\n",
    "pil_image = Image.fromarray(imagen)\n",
    "small_frame = cv2.resize(imagen, (0, 0), fx=0.25, fy=0.25)\n",
    "toll1 = pil_image.size[1]//38\n",
    "toll2 = pil_image.size[1]//39\n",
    "print(toll1,toll2)\n",
    "if apertura_sx+apertura_dx<20:\n",
    "    print(\"troppo lontano\")\n",
    "else:\n",
    "    if apertura_dx <= toll2 or apertura_sx <= toll2:\n",
    "        print(\"qualche occhio chiuso\")\n",
    "    else:\n",
    "        if apertura_dx <= toll1 or apertura_sx <= toll1:\n",
    "            print(\"qualche occhio chiuso\")\n",
    "        else:\n",
    "            print(\"nessun occhio chiuso\")\n",
    "    \n",
    "d = ImageDraw.Draw(pil_image, 'RGBA')\n",
    "\n",
    "d.line(face_landmarks_list[0][\"left_eye\"][4]+ face_landmarks_list[0][\"left_eye\"][2], fill=(0, 0, 0, 110), width=6)\n",
    "d.line(face_landmarks_list[0][\"right_eye\"][4]+ face_landmarks_list[0][\"right_eye\"][2], fill=(0, 0, 0, 110), width=6)\n",
    "d.line(face_landmarks_list[0]['bottom_lip'], fill=(0, 0, 0, 110), width=6)\n",
    "\n",
    "cv.imshow(\"frame\", small_frame[int(face_locations[0][0]):int(face_locations[0][2]), int(face_locations[0][1]):int(face_locations[0][3])])\n",
    "cv.waitKey(0) \n",
    "  \n",
    "#closing all open windows \n",
    "cv.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "066ea8bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'known_face_encodings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20340/1703014760.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface_encoding\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface_encodings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# See if the face is a match for the known face(s)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompare_faces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknown_face_encodings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface_encoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Unknown\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'known_face_encodings' is not defined"
     ]
    }
   ],
   "source": [
    "capture = cv.VideoCapture(0)\n",
    "ochiolino = False\n",
    "sorriso = False\n",
    "sblocco = False\n",
    "while(True):\n",
    "      \n",
    "    # Capture the video frame\n",
    "    # by frame\n",
    "    ret, frame = capture.read()\n",
    "    rgb_frame = frame[:, :, ::-1]  \n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "    face_landmarks_list = face_recognition.face_landmarks(frame)\n",
    "    \n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        # See if the face is a match for the known face(s)\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        # If a match was found in known_face_encodings, just use the first one.\n",
    "        if True in matches:\n",
    "            first_match_index = matches.index(True)\n",
    "            name = known_face_names[first_match_index]\n",
    "            sblocco = True\n",
    "        else:\n",
    "            sblocco = False     \n",
    "        # Or instead, use the known face with the smallest distance to the new face\n",
    "        # face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "        # best_match_index = np.argmin(face_distances)\n",
    "        # if matches[best_match_index]:\n",
    "           #  name = known_face_names[best_match_index]\n",
    "            \n",
    "        \n",
    "    # Display the resulting frame\n",
    "    cv.imshow('frame', frame)\n",
    "    if sblocco:\n",
    "        face_landmarks_list = face_recognition.face_landmarks(frame)\n",
    "        apertura_sx = abs(face_landmarks_list[0][\"left_eye\"][4][1] - face_landmarks_list[0][\"left_eye\"][2][1])\n",
    "        apertura_dx = abs(face_landmarks_list[0][\"right_eye\"][4][1] - face_landmarks_list[0][\"right_eye\"][2][1])\n",
    "        pil_image = Image.fromarray(rgb_frame)\n",
    "        toll1 = pil_image.size[1]//45\n",
    "        toll2 = pil_image.size[1]/45\n",
    "        if apertura_sx+apertura_dx<20:\n",
    "            print(\"troppo lontano\")\n",
    "        else:\n",
    "            if apertura_dx <= toll2 or apertura_sx <= toll2:\n",
    "                ochiolino = True\n",
    "                print(\"occhiolino\")\n",
    "            else:\n",
    "                if apertura_dx <= toll1 or apertura_sx <= toll1:\n",
    "                    ochiolino = True\n",
    "                    print(\"occhiolino\")\n",
    "                else:\n",
    "                    print(\"nessun occhio chiuso\")\n",
    "    if cv.waitKey(1) & 0xFF == ord('q') or (ochiolino and sblocco):\n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object\n",
    "capture.release()\n",
    "# Destroy all the windows\n",
    "cv.destroyAllWindows()\n",
    "time.sleep(0.02)\n",
    "print(\".\\n\")\n",
    "time.sleep(0.02)\n",
    "print(\".\\n\")\n",
    "time.sleep(0.02)\n",
    "print(\".\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "006edd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lands[]\n",
      "\n",
      "apertura15\n",
      "\n",
      "apertura11\n",
      "\n",
      "toll110\n",
      "\n",
      "toll210.666666666666666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"lands{face_landmarks_list}\\n\") \n",
    "print(f\"apertura{apertura_sx}\\n\")\n",
    "print(f\"apertura{apertura_dx}\\n\")\n",
    "print(f\"toll1{toll1}\\n\")\n",
    "print(f\"toll2{toll2}\\n\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fc32d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sblocco\n",
      "occhiolino\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cap = cv.VideoCapture('myvideo.mp4')\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    rgb_frame = frame[:, :, ::-1]  \n",
    "    new_encoding = face_recognition.face_encodings(frame)[0]\n",
    "    sblocco = face_recognition.compare_faces([leo_face_encoding], new_encoding)\n",
    "    # Display the resulting frame\n",
    "    cv.imshow('frame', frame)\n",
    "    if sblocco:\n",
    "        face_landmarks_list = face_recognition.face_landmarks(frame)\n",
    "        print(\"sblocco\")\n",
    "        face_landmarks_list = face_recognition.face_landmarks(frame)\n",
    "        apertura_sx = abs(face_landmarks_list[0][\"left_eye\"][4][1] - face_landmarks_list[0][\"left_eye\"][2][1])\n",
    "        apertura_dx = abs(face_landmarks_list[0][\"right_eye\"][4][1] - face_landmarks_list[0][\"right_eye\"][2][1])\n",
    "        pil_image = Image.fromarray(rgb_frame)\n",
    "        toll1 = pil_image.size[1]//45\n",
    "        toll2 = pil_image.size[1]/45\n",
    "        if apertura_sx+apertura_dx<20:\n",
    "            print(\"troppo lontano\")\n",
    "        else:\n",
    "            if apertura_dx <= toll2 or apertura_sx <= toll2:\n",
    "                ochiolino = True\n",
    "                print(\"occhiolino\")\n",
    "                time.sleep(0.02)\n",
    "            else:\n",
    "                if apertura_dx <= toll1 or apertura_sx <= toll1:\n",
    "                    ochiolino = True\n",
    "                    print(\"occhiolino\")\n",
    "                    time.sleep(0.02)\n",
    "                else:\n",
    "                    print(\"nessun occhio chiuso\")\n",
    "    if cv.waitKey(1) & 0xFF == ord('q') or (ochiolino and sblocco):\n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object\n",
    "cap.release()\n",
    "time.sleep(20)\n",
    "# Destroy all the windows\n",
    "cv.destroyAllWindows()\n",
    "time.sleep(0.02)\n",
    "print(\".\\n\")\n",
    "time.sleep(0.02)\n",
    "print(\".\\n\")\n",
    "time.sleep(0.02)\n",
    "print(\".\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66c7c551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "occhiolino\n",
      "apertura dx: 12\n",
      "apertura sx: 13\n",
      "toll: 12\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "troppo lontano\n",
      "troppo lontano\n",
      "troppo lontano\n",
      "troppo lontano\n",
      "troppo lontano\n",
      "troppo lontano\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "troppo lontano\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "troppo lontano\n",
      "troppo lontano\n",
      "troppo lontano\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "occhiolino\n",
      "apertura dx: 14\n",
      "apertura sx: 16\n",
      "toll: 14\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "22\n",
      "23\n",
      "14\n",
      "False\n",
      "385\n",
      "385\n",
      "2560\n",
      "1920\n",
      "[(504, 1317, 889, 932)]\n",
      "[{'chin': [(29, 114), (35, 161), (42, 207), (51, 254), (64, 300), (87, 341), (117, 374), (153, 396), (199, 402), (249, 397), (293, 378), (331, 344), (361, 303), (378, 256), (385, 204), (388, 153), (390, 99)], 'left_eyebrow': [(43, 87), (59, 62), (90, 53), (123, 56), (156, 67)], 'right_eyebrow': [(203, 60), (239, 45), (279, 39), (318, 47), (346, 71)], 'nose_bridge': [(179, 103), (178, 137), (177, 171), (175, 206)], 'nose_tip': [(148, 233), (164, 238), (183, 241), (203, 236), (224, 230)], 'left_eye': [(74, 115), (91, 103), (116, 101), (139, 116), (115, 124), (90, 125)], 'right_eye': [(238, 109), (259, 93), (285, 92), (308, 102), (287, 114), (262, 115)], 'top_lip': [(131, 301), (149, 292), (169, 286), (187, 290), (204, 284), (231, 288), (261, 295), (249, 297), (206, 300), (187, 303), (169, 301), (139, 302)], 'bottom_lip': [(261, 295), (235, 316), (210, 325), (191, 328), (172, 327), (150, 320), (131, 301), (139, 302), (171, 303), (189, 305), (207, 302), (249, 297)]}]\n",
      "227.11706233024597\n"
     ]
    }
   ],
   "source": [
    "# occhiolino con scaling funzionante\n",
    "\n",
    "import face_recognition\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import time\n",
    "t0 = time.time()\n",
    "path = \"photos/leo.jpg\"\n",
    "cattura = \"Doorbell1.mp4\"\n",
    "# \"myvideo.mp4\" \"occhiolino.mp4\" \"Doorbell1.mp4\"\n",
    "image = face_recognition.load_image_file(path)\n",
    "try:\n",
    "    face_encoding = face_recognition.face_encodings(image)[0]\n",
    "except Error:\n",
    "    print(\"I didn't any faces, quitting...\\n\")\n",
    "    time.sleep(0.02)\n",
    "    print(\".\\n\")\n",
    "    time.sleep(0.02)\n",
    "    print(\".\\n\")\n",
    "    time.sleep(0.02)\n",
    "    print(\".\\n\")\n",
    "    \n",
    "    \n",
    "cap = cv.VideoCapture(cattura)\n",
    "\n",
    "ret, frame = cap.read()    \n",
    "\n",
    "arr = Image.fromarray(frame)\n",
    "if arr.size[0] < 500 and arr.size[1] < 300:\n",
    "    print(\"qualità troppo bassa impossibile misurare correttamente\")\n",
    "    exit()\n",
    "while(True):\n",
    "    apertura_sx = 0\n",
    "    apertura_dx = 0\n",
    "    ochiolino = False\n",
    "    sblocco = [False]\n",
    "    ret, frame = cap.read()    \n",
    "    if not ret:\n",
    "        break\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    if face_locations:\n",
    "        top, right, bottom, left = face_locations[0]\n",
    "        crop_frame = frame[top:bottom, left:right]\n",
    "        crop_image = Image.fromarray(crop_frame)\n",
    "        if crop_image.size[0] < 150 and crop_image.size[1] < 100:\n",
    "            print(\"qualità troppo bassa impossibile misurare correttamente\")\n",
    "            break\n",
    "        if crop_image.size[0] < 700 and crop_image.size[1] < 500:\n",
    "            res_frame = crop_frame\n",
    "        else: \n",
    "            res_frame = cv.resize(crop_frame, (150, 200))\n",
    "            \n",
    "        cv.imshow(\"frame prova\", res_frame)\n",
    "        try:\n",
    "            new_encoding = face_recognition.face_encodings(frame)[0]\n",
    "            sblocco = face_recognition.compare_faces([face_encoding], new_encoding)\n",
    "        except:\n",
    "            sblocco = [False]\n",
    "        sblocco = [True]\n",
    "        if sblocco[0]:\n",
    "            face_landmarks_list = face_recognition.face_landmarks(res_frame)\n",
    "            if face_landmarks_list: \n",
    "                if face_landmarks_list[0]:\n",
    "                    apertura_sx = abs(face_landmarks_list[0][\"left_eye\"][4][1] - face_landmarks_list[0][\"left_eye\"][2][1])\n",
    "                    apertura_dx = abs(face_landmarks_list[0][\"right_eye\"][4][1] - face_landmarks_list[0][\"right_eye\"][2][1])\n",
    "            pil_image = Image.fromarray(res_frame)\n",
    "            pil_image_real = Image.fromarray(frame)\n",
    "            toll1 = pil_image.size[1]//26\n",
    "            \n",
    "            if apertura_sx+apertura_dx<5:\n",
    "                print(\"troppo lontano\")\n",
    "            else:\n",
    "                if (apertura_dx <= toll1 and apertura_sx > toll1):\n",
    "                    ochiolino = True\n",
    "                    print(\"occhiolino\")\n",
    "                    print(f\"apertura dx: {apertura_dx}\")\n",
    "                    print(f\"apertura sx: {apertura_sx}\")\n",
    "                    print(f\"toll: {toll1}\")\n",
    "                    \n",
    "                    time.sleep(0.02)\n",
    "                else:\n",
    "                    if (apertura_sx <= toll1 and apertura_dx > toll1):\n",
    "                        ochiolino = True\n",
    "                        print(\"occhiolino\")\n",
    "                        print(f\"apertura dx: {apertura_dx}\")\n",
    "                        print(f\"apertura sx: {apertura_sx}\")\n",
    "                        print(f\"toll: {toll1}\")\n",
    "                        \n",
    "                    else:    \n",
    "                        print(\"nessun occhio chiuso\")\n",
    "    if face_locations:\n",
    "        cv.imshow(\"frame\", res_frame)\n",
    "    else:\n",
    "        cv.imshow(\"frame\", frame)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "# Destroy all the windows\n",
    "time.sleep(0.2)\n",
    "print(\".\\n\")\n",
    "time.sleep(0.2)\n",
    "print(\".\\n\")\n",
    "time.sleep(0.2)\n",
    "print(\".\\n\")\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "print(apertura_dx)\n",
    "print(apertura_sx)\n",
    "print(toll1)\n",
    "print(ochiolino)\n",
    "print(pil_image.size[0])\n",
    "print(pil_image.size[1])\n",
    "print(pil_image_real.size[0])\n",
    "print(pil_image_real.size[1])\n",
    "print(face_locations)\n",
    "print(face_landmarks_list)\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "283b907c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n",
      "267\n",
      "[(504, 1317, 889, 932)]\n",
      "11\n",
      "10\n",
      "7\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'toll2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4656/443269304.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapertura_sx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoll1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoll2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mochiolino\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpil_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'toll2' is not defined"
     ]
    }
   ],
   "source": [
    "# printaggio brutto \n",
    "print(crop_image.size[0])\n",
    "print(crop_image.size[1])\n",
    "\n",
    "\n",
    "\n",
    "cv.imshow('image',crop_frame) \n",
    "\n",
    "cv.imshow('frame',frame)\n",
    "\n",
    "cv.waitKey(0) \n",
    "\n",
    "\n",
    "\n",
    "face_locations = face_recognition.face_locations(frame)\n",
    "print(face_locations)\n",
    "\n",
    "\n",
    "print(apertura_dx)\n",
    "print(apertura_sx)\n",
    "print(toll1)\n",
    "print(toll2)\n",
    "print(ochiolino)\n",
    "print(pil_image.size[0])\n",
    "print(pil_image.size[1])\n",
    "print(pil_image_real.size[0])\n",
    "print(pil_image_real.size[1])\n",
    "print(face_locations)\n",
    "print(face_landmarks_list)\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d00e267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "nessun occhio chiuso\n",
      "occhiolino\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "nessun occhio chiuso\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "nessun occhio chiuso\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      "occhiolino\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "10\n",
      "13\n",
      "18\n",
      "18.46153846153846\n",
      "True\n",
      "640\n",
      "480\n",
      "640\n",
      "480\n",
      "[(82, 617, 350, 349)]\n",
      "[{'chin': [(326, 197), (328, 236), (332, 276), (338, 312), (357, 343), (388, 363), (428, 375), (467, 381), (504, 385), (533, 380), (553, 365), (566, 343), (572, 317), (576, 290), (577, 264), (576, 239), (574, 217)], 'left_eyebrow': [(381, 150), (405, 127), (438, 115), (474, 117), (504, 132)], 'right_eyebrow': [(515, 139), (535, 132), (556, 137), (573, 151), (576, 174)], 'nose_bridge': [(512, 157), (518, 169), (524, 180), (530, 194)], 'nose_tip': [(489, 231), (503, 233), (517, 235), (528, 235), (537, 233)], 'left_eye': [(417, 167), (434, 159), (451, 159), (466, 171), (450, 172), (434, 171)], 'right_eye': [(526, 179), (540, 175), (553, 180), (560, 191), (551, 190), (538, 186)], 'top_lip': [(451, 289), (479, 271), (502, 262), (516, 266), (530, 264), (540, 276), (545, 298), (539, 294), (528, 282), (515, 281), (500, 280), (461, 287)], 'bottom_lip': [(545, 298), (538, 304), (526, 306), (512, 306), (497, 304), (476, 297), (451, 289), (461, 287), (501, 285), (515, 288), (528, 288), (539, 294)]}]\n",
      "34.02162051200867\n"
     ]
    }
   ],
   "source": [
    "# occhiolino senza scaling funzionante\n",
    "\n",
    "import face_recognition\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import time\n",
    "t0 = time.time()\n",
    "path = \"photos/leo.jpg\"\n",
    "cattura = 0\n",
    "# \"myvideo.mp4\" \"occhiolino.mp4\"\"Doorbell1.mp4\"\n",
    "image = face_recognition.load_image_file(path)\n",
    "try:\n",
    "    face_encoding = face_recognition.face_encodings(image)[0]\n",
    "except Error:\n",
    "    print(\"I didn't any faces, quitting...\\n\")\n",
    "    time.sleep(0.02)\n",
    "    print(\".\\n\")\n",
    "    time.sleep(0.02)\n",
    "    print(\".\\n\")\n",
    "    time.sleep(0.02)\n",
    "    print(\".\\n\")\n",
    "    \n",
    "    \n",
    "cap = cv.VideoCapture(cattura)\n",
    "\n",
    "ret, frame = cap.read()    \n",
    "\n",
    "arr = Image.fromarray(frame)\n",
    "if arr.size[0] < 500 and arr.size[1] < 300:\n",
    "    print(\"qualità troppo bassa impossibile misurare correttamente\")\n",
    "    exit()\n",
    "while(True):\n",
    "    apertura_sx = 0\n",
    "    apertura_dx = 0\n",
    "    ochiolino = False\n",
    "    sblocco = [False]\n",
    "    ret, frame = cap.read()    \n",
    "    if not ret:\n",
    "        break\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    if face_locations:\n",
    "        \n",
    "        try:\n",
    "            new_encoding = face_recognition.face_encodings(frame)[0]\n",
    "            sblocco = face_recognition.compare_faces([face_encoding], new_encoding)\n",
    "        except:\n",
    "            sblocco = [False]\n",
    "            \n",
    "        sblocco = [True]\n",
    "        if sblocco[0]:\n",
    "            face_landmarks_list = face_recognition.face_landmarks(frame)\n",
    "            if face_landmarks_list: \n",
    "                if face_landmarks_list[0]:\n",
    "                    apertura_sx = abs(face_landmarks_list[0][\"left_eye\"][4][1] - face_landmarks_list[0][\"left_eye\"][2][1])\n",
    "                    apertura_dx = abs(face_landmarks_list[0][\"right_eye\"][4][1] - face_landmarks_list[0][\"right_eye\"][2][1])\n",
    "            pil_image = Image.fromarray(frame)\n",
    "            pil_image_real = Image.fromarray(frame)\n",
    "            toll1 = pil_image.size[1]//26\n",
    "            toll2 = pil_image.size[1]/26\n",
    "            if apertura_sx+apertura_dx<5:\n",
    "                print(\"troppo lontano\")\n",
    "            else:\n",
    "                if apertura_dx <= toll2 or apertura_sx <= toll2:\n",
    "                    ochiolino = True\n",
    "                    print(\"occhiolino\")\n",
    "                    time.sleep(0.02)\n",
    "                else:\n",
    "                    if apertura_dx <= toll1 or apertura_sx <= toll1:\n",
    "                        ochiolino = True\n",
    "                        print(\"occhiolino\")\n",
    "                        time.sleep(0.02)\n",
    "                    else:\n",
    "                        print(\"nessun occhio chiuso\")\n",
    "    if face_locations:\n",
    "        cv.imshow(\"frame\", frame)\n",
    "    else:\n",
    "        cv.imshow(\"frame\", frame)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "# Destroy all the windows\n",
    "time.sleep(0.2)\n",
    "print(\".\\n\")\n",
    "time.sleep(0.2)\n",
    "print(\".\\n\")\n",
    "time.sleep(0.2)\n",
    "print(\".\\n\")\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "print(apertura_dx)\n",
    "print(apertura_sx)\n",
    "print(toll1)\n",
    "print(toll2)\n",
    "print(ochiolino)\n",
    "print(pil_image.size[0])\n",
    "print(pil_image.size[1])\n",
    "print(pil_image_real.size[0])\n",
    "print(pil_image_real.size[1])\n",
    "print(face_locations)\n",
    "print(face_landmarks_list)\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425071fb",
   "metadata": {},
   "source": [
    "# kek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b121db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "\n",
    "# Load the jpg file into a numpy array\n",
    "\n",
    "res_frame = face_recognition.load_image_file(\"photos/maur_wink_smile.png\")\n",
    "# Find all facial features in all the faces in the image\n",
    "face_landmarks_list = face_recognition.face_landmarks(res_frame)\n",
    "\n",
    "pil_image = Image.fromarray(res_frame)\n",
    "\n",
    "d = ImageDraw.Draw(pil_image, 'RGBA')\n",
    "\n",
    "# Make the eyebrows into a nightmare\n",
    "\n",
    "# Gloss the lips\n",
    "# print(face_landmarks_list[0]['top_lip'][0])\n",
    "# d.line([face_landmarks_list[0]['left_eye'][4],face_landmarks_list[0]['left_eye'][2]], width=10, fill=(0, 150, 0, 64))\n",
    "\n",
    "# d.line([face_landmarks_list[0]['left_eye'][5],face_landmarks_list[0]['left_eye'][1]], width=10, fill=(0, 0, 150, 64))\n",
    "\n",
    "# d.line([face_landmarks_list[0]['left_eye'][0],face_landmarks_list[0]['left_eye'][3]], width=10, fill=(150, 0, 0, 64))\n",
    "\n",
    "#d.line(face_landmarks_list[0]['top_lip'], width=10, fill=(150, 0, 0, 64))\n",
    "#d.line(face_landmarks_list[0]['bottom_lip'], width=10, fill=(150, 0, 0, 64))\n",
    "d.line([face_landmarks_list[0]['top_lip'][0],(face_landmarks_list[0]['top_lip'][0][0],0)], fill=(0, 0, 150, 64), width=5)\n",
    "d.line([face_landmarks_list[0]['top_lip'][2],(face_landmarks_list[0]['top_lip'][2][0],0)], fill=(0, 150, 0, 64), width=5)\n",
    "d.line([face_landmarks_list[0]['top_lip'][4],(face_landmarks_list[0]['top_lip'][4][0],0)], fill=(0, 150, 150, 64), width=5)\n",
    "d.line([face_landmarks_list[0]['top_lip'][6],(face_landmarks_list[0]['top_lip'][6][0],0)], fill=(0, 0, 150, 64), width=5)\n",
    "#d.line([face_landmarks_list[0]['top_lip'][10],(face_landmarks_list[0]['top_lip'][10][0],0)], fill=(150, 150, 0, 64), width=5)\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aa536cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "6\n",
      "9\n",
      "True\n",
      "2\n",
      "156.13028478622437\n"
     ]
    }
   ],
   "source": [
    "# sorriso e occhiolino con scaling funzionante\n",
    "\n",
    "import face_recognition\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import time\n",
    "framec = 0;\n",
    "\n",
    "path = \"photos/leo.jpg\"\n",
    "cattura = 0 \n",
    "# \"myvideo.mp4\" \"Doorbell2.mp4\" \"Doorbell1.mp4\" \"occhiolino.mp4\" \"Doorbell1.mp4\" \"leo_wink_smile.mp4\"\n",
    "imagel = face_recognition.load_image_file(path)\n",
    "imagea = face_recognition.load_image_file(\"photos/ma.png\")\n",
    "try:\n",
    "    leo_face_encoding = face_recognition.face_encodings(imagel)[0]\n",
    "    ma_face_encoding = face_recognition.face_encodings(imagea)[0]\n",
    "except Error:\n",
    "    print(\"I didn't any faces, quitting...\\n\")\n",
    "    time.sleep(0.02)\n",
    "    print(\".\\n\")\n",
    "    time.sleep(0.02)\n",
    "    print(\".\\n\")\n",
    "    time.sleep(0.02)\n",
    "    print(\".\\n\")\n",
    "    \n",
    "known_face_encodings = [\n",
    "    leo_face_encoding,\n",
    "    ma_face_encoding\n",
    "]\n",
    "cap = cv.VideoCapture(cattura)\n",
    "ret, frame = cap.read()\n",
    "apertura_sx = 0\n",
    "apertura_dx = 0\n",
    "toll1 = 2\n",
    "sblocco = [False]\n",
    "sorriso = False\n",
    "occhiolino = False\n",
    "cfs = 0\n",
    "cfo = 0\n",
    "arr = Image.fromarray(frame)\n",
    "if arr.size[0] < 500 and arr.size[1] < 300:\n",
    "    print(\"qualità troppo bassa impossibile misurare correttamente\")\n",
    "    exit()\n",
    "t0 = time.time()\n",
    "while(True):\n",
    "    sblocco = [False,False]\n",
    "    ret, frame = cap.read()    \n",
    "    if not ret:\n",
    "        break\n",
    "    if framec % 2 == 0:\n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "    else:\n",
    "        face_locations = []\n",
    "    if face_locations:\n",
    "        top, right, bottom, left = face_locations[0]\n",
    "        crop_frame = frame[top-50:bottom+50,left:right]\n",
    "        try:\n",
    "            res_frame = cv.resize(crop_frame, (200, 300))\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            new_encoding = face_recognition.face_encodings(res_frame)[0]\n",
    "            sblocco = face_recognition.compare_faces(known_face_encodings, new_encoding)\n",
    "        except:\n",
    "            sblocco = [False,False]\n",
    "        if True in sblocco:\n",
    "            face_landmarks_list = face_recognition.face_landmarks(res_frame)\n",
    "            if face_landmarks_list: \n",
    "                if face_landmarks_list[0]:\n",
    "                    \n",
    "                    apertura_sx = abs(face_landmarks_list[0][\"left_eye\"][4][1] - face_landmarks_list[0][\"left_eye\"][2][1])\n",
    "                    apertura_dx = abs(face_landmarks_list[0][\"right_eye\"][4][1] - face_landmarks_list[0][\"right_eye\"][2][1])\n",
    "                    if ((apertura_sx <= (apertura_dx-toll1)) \n",
    "                        or (apertura_dx <= (apertura_sx-toll1))):\n",
    "                        occhiolino = True\n",
    "                    else:\n",
    "                        cfo += 1\n",
    "                        if cfo == 2 :\n",
    "                            occhiolino = False\n",
    "                            cfo = 0\n",
    "                    if ((face_landmarks_list[0]['bottom_lip'][7][1]+toll1*4< face_landmarks_list[0]['bottom_lip'][9][1]) \n",
    "                    or (face_landmarks_list[0]['bottom_lip'][11][1]+toll1*4< face_landmarks_list[0]['bottom_lip'][9][1])\n",
    "                    and abs(face_landmarks_list[0][\"bottom_lip\"][9][1] - face_landmarks_list[0][\"top_lip\"][9][1]) > toll1*2): \n",
    "                        sorriso = True\n",
    "                    else:\n",
    "                        cfs += 1\n",
    "                        if cfs == 2 :\n",
    "                            sorriso = False\n",
    "                            cfs = 0\n",
    "    if framec % 2 == 0 and face_locations:\n",
    "        font = cv.FONT_HERSHEY_SIMPLEX\n",
    "        cv.putText(res_frame, f'fps: {framec/(time.time()-t0)}', (140,10), font, 0.3, (0, 255, 0), 1, cv.LINE_AA)\n",
    "        cv.putText(res_frame, f'Pass: {sblocco[0]};{occhiolino};{sorriso}', (10,10), font, 0.3, (0, 255, 0), 1, cv.LINE_AA)\n",
    "        res_frame = cv.resize(res_frame, (600, 800))\n",
    "        cv.imshow(\"frame\", res_frame)\n",
    "    if cv.waitKey(1) & 0xFF == ord('q') or (True in sblocco and occhiolino and sorriso):\n",
    "        break\n",
    "    framec += 1\n",
    "    \n",
    "cap.release()\n",
    "# Destroy all the windows\n",
    "time.sleep(0.2)\n",
    "print(\".\\n\")\n",
    "time.sleep(0.2)\n",
    "print(\".\\n\")\n",
    "time.sleep(0.2)\n",
    "print(\".\\n\")\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "print(apertura_dx)\n",
    "print(apertura_sx)\n",
    "print(occhiolino)\n",
    "print(toll1)\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc214f66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "not scaled and cropped test...\n",
      "unlocked at:       1.0119948387145996\n",
      "wink at:           1.6179945468902588\n",
      "smile at:          1.6179945468902588\n",
      "test concluded in: 1.6179945468902588\n",
      "image dimensions:  (1280, 959, 3) toll: 19 sx: 15 dx: 21\n",
      "\n",
      "cropped test...\n",
      "unlocked at:       1.1320011615753174\n",
      "wink at:           1.2669987678527832\n",
      "smile at:          1.2669987678527832\n",
      "test concluded in: 1.2669987678527832\n",
      "image dimensions:  (563, 462, 3) toll: 19 sx: 15 dx: 21\n",
      "\n",
      "scaled and cropped test...\n",
      "unlocked at:       1.0749702453613281\n",
      "wink at:           1.14096999168396\n",
      "smile at:          1.14096999168396\n",
      "test concluded in: 1.14096999168396\n",
      "image dimensions:  (400, 300, 3) toll: 2 sx: 11 dx: 14\n"
     ]
    }
   ],
   "source": [
    "# test velocità riconoscimento facciale e features\n",
    "import face_recognition\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "imagel = face_recognition.load_image_file(\"photos/leo.jpg\")\n",
    "imagea = face_recognition.load_image_file(\"photos/ma.png\")\n",
    "try:\n",
    "    leo_face_encoding = face_recognition.face_encodings(imagel)[0]\n",
    "    ma_face_encoding = face_recognition.face_encodings(imagea)[0]\n",
    "except Error:\n",
    "    print(\"I didn't any faces, quitting...\\n\")\n",
    "    time.sleep(0.02)\n",
    "    print(\".\\n\")\n",
    "    time.sleep(0.02)\n",
    "    print(\".\\n\")\n",
    "    time.sleep(0.02)\n",
    "    print(\".\\n\")\n",
    "    \n",
    "known_face_encodings = [\n",
    "    leo_face_encoding,\n",
    "    ma_face_encoding\n",
    "]\n",
    "occhiolino = False\n",
    "sorriso = False\n",
    "sblocco = [False]\n",
    "t_start = 0\n",
    "t_sblocco = 0\n",
    "t_occhiolino = 0\n",
    "t_sorriso = 0\n",
    "img = cv.imread('photos/smile_wink.jpg', cv.IMREAD_UNCHANGED)\n",
    "toll1 = 19 # euristico\n",
    "uno = img\n",
    "\n",
    "t_start = time.time()\n",
    "image = face_recognition.load_image_file(\"photos/smile_wink.jpg\")\n",
    "new_encoding = face_recognition.face_encodings(image)[0]\n",
    "sblocco = face_recognition.compare_faces(known_face_encodings, new_encoding)\n",
    "if True in sblocco: t_sblocco = time.time()\n",
    "face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "apertura_sx = abs(face_landmarks_list[0][\"left_eye\"][4][1] - face_landmarks_list[0][\"left_eye\"][2][1])\n",
    "apertura_dx = abs(face_landmarks_list[0][\"right_eye\"][4][1] - face_landmarks_list[0][\"right_eye\"][2][1])\n",
    "occhiolino = apertura_sx < toll1 or apertura_dx < toll1\n",
    "if occhiolino: t_occhiolino = time.time()\n",
    "sorriso = ((face_landmarks_list[0]['bottom_lip'][7][1]+toll1*4< face_landmarks_list[0]['bottom_lip'][9][1]) \n",
    "                    or (face_landmarks_list[0]['bottom_lip'][11][1]+toll1*4< face_landmarks_list[0]['bottom_lip'][9][1])\n",
    "                    or abs(face_landmarks_list[0][\"bottom_lip\"][9][1] - face_landmarks_list[0][\"top_lip\"][9][1]) > toll1*2)\n",
    "if sorriso: t_sorriso = time.time()\n",
    "t_end = time.time()\n",
    "print((face_landmarks_list[0]['bottom_lip'][7][1]+toll1*4< face_landmarks_list[0]['bottom_lip'][9][1]) )\n",
    "print((face_landmarks_list[0]['bottom_lip'][11][1]+toll1*4< face_landmarks_list[0]['bottom_lip'][9][1]))\n",
    "print(abs(face_landmarks_list[0][\"bottom_lip\"][9][1] - face_landmarks_list[0][\"top_lip\"][9][1]) > toll1*2)\n",
    "\n",
    "print(\"not scaled and cropped test...\")\n",
    "if True in sblocco: print(f\"unlocked at:       {t_sblocco - t_start}\") \n",
    "else: print(\"errore\")\n",
    "if occhiolino: print(f\"wink at:           {t_occhiolino - t_start}\") \n",
    "else: print(\"errore\")\n",
    "if sorriso: print(f\"smile at:          {t_sorriso - t_start}\") \n",
    "else: print(\"errore\")\n",
    "print(f\"test concluded in: {t_end - t_start}\")\n",
    "print(f\"image dimensions:  {image.shape} toll: {toll1} sx: {apertura_sx} dx: {apertura_dx}\")\n",
    "\n",
    "occhiolino = False\n",
    "sorriso = False\n",
    "sblocco = [False]\n",
    "t_start = 0\n",
    "t_sblocco = 0\n",
    "t_occhiolino = 0\n",
    "t_sorriso = 0\n",
    "img = cv.imread('photos/smile_wink.jpg')\n",
    "toll1 = 19 # euristico\n",
    "\n",
    "\n",
    "t_start = time.time()\n",
    "image = face_recognition.load_image_file(\"photos/smile_wink.jpg\")\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "top, right, bottom, left = face_locations[0]\n",
    "crop_frame = img[top-50:bottom+50,left:right]\n",
    "res_frame = crop_frame\n",
    "new_encoding = face_recognition.face_encodings(res_frame)[0]\n",
    "sblocco = face_recognition.compare_faces(known_face_encodings, new_encoding)\n",
    "if True in sblocco: t_sblocco = time.time()\n",
    "face_landmarks_list = face_recognition.face_landmarks(res_frame)\n",
    "apertura_sx = abs(face_landmarks_list[0][\"left_eye\"][4][1] - face_landmarks_list[0][\"left_eye\"][2][1])\n",
    "apertura_dx = abs(face_landmarks_list[0][\"right_eye\"][4][1] - face_landmarks_list[0][\"right_eye\"][2][1])\n",
    "occhiolino = apertura_sx < toll1 or apertura_dx < toll1\n",
    "if occhiolino: t_occhiolino = time.time()\n",
    "sorriso = ((face_landmarks_list[0]['bottom_lip'][7][1]+toll1*4< face_landmarks_list[0]['bottom_lip'][9][1]) \n",
    "                    or (face_landmarks_list[0]['bottom_lip'][11][1]+toll1*4< face_landmarks_list[0]['bottom_lip'][9][1])\n",
    "                    or abs(face_landmarks_list[0][\"bottom_lip\"][9][1] - face_landmarks_list[0][\"top_lip\"][9][1]) > toll1*2)\n",
    "if sorriso: t_sorriso = time.time()\n",
    "t_end = time.time()\n",
    "print(\"\\ncropped test...\")\n",
    "if True in sblocco: print(f\"unlocked at:       {t_sblocco - t_start}\") \n",
    "else: print(\"errore\")\n",
    "if occhiolino: print(f\"wink at:           {t_occhiolino - t_start}\") \n",
    "else: print(\"errore\")\n",
    "if sorriso: print(f\"smile at:          {t_sorriso - t_start}\") \n",
    "else: print(\"errore\")\n",
    "print(f\"test concluded in: {t_end - t_start}\")\n",
    "print(f\"image dimensions:  {res_frame.shape} toll: {toll1} sx: {apertura_sx} dx: {apertura_dx}\")\n",
    "\n",
    "due = res_frame\n",
    "\n",
    "occhiolino = False\n",
    "sorriso = False\n",
    "sblocco = [False]\n",
    "t_start = 0\n",
    "t_sblocco = 0\n",
    "t_occhiolino = 0\n",
    "t_sorriso = 0\n",
    "img = cv.imread('photos/smile_wink.jpg')\n",
    "toll1 = 2 # euristico\n",
    "\n",
    "\n",
    "t_start = time.time()\n",
    "image = face_recognition.load_image_file(\"photos/smile_wink.jpg\")\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "top, right, bottom, left = face_locations[0]\n",
    "crop_frame = img[top-50:bottom+50,left:right]\n",
    "res_frame = cv.resize(crop_frame, (300, 400))\n",
    "new_encoding = face_recognition.face_encodings(res_frame)[0]\n",
    "sblocco = face_recognition.compare_faces(known_face_encodings, new_encoding)\n",
    "if True in sblocco: t_sblocco = time.time()\n",
    "face_landmarks_list = face_recognition.face_landmarks(res_frame)    \n",
    "apertura_sx = abs(face_landmarks_list[0][\"left_eye\"][4][1] - face_landmarks_list[0][\"left_eye\"][2][1])\n",
    "apertura_dx = abs(face_landmarks_list[0][\"right_eye\"][4][1] - face_landmarks_list[0][\"right_eye\"][2][1])\n",
    "occhiolino = ((apertura_sx <= (apertura_dx-toll1)) \n",
    "                        or (apertura_dx <= (apertura_sx-toll1)))\n",
    "if occhiolino: t_occhiolino = time.time()\n",
    "sorriso = ((face_landmarks_list[0]['bottom_lip'][7][1]+toll1*4< face_landmarks_list[0]['bottom_lip'][9][1]) \n",
    "                    or (face_landmarks_list[0]['bottom_lip'][11][1]+toll1*4< face_landmarks_list[0]['bottom_lip'][9][1])\n",
    "                    or abs(face_landmarks_list[0][\"bottom_lip\"][9][1] - face_landmarks_list[0][\"top_lip\"][9][1]) > toll1*2)\n",
    "if sorriso: t_sorriso = time.time()\n",
    "t_end = time.time()\n",
    "\n",
    "tre = res_frame\n",
    "print(\"\\nscaled and cropped test...\")\n",
    "if True in sblocco: print(f\"unlocked at:       {t_sblocco - t_start}\") \n",
    "else: print(\"errore\")\n",
    "if occhiolino: print(f\"wink at:           {t_occhiolino - t_start}\") \n",
    "else: print(\"errore\")\n",
    "if sorriso: print(f\"smile at:          {t_sorriso - t_start}\") \n",
    "else: print(\"errore\")\n",
    "print(f\"test concluded in: {t_end - t_start}\")\n",
    "print(f\"image dimensions:  {res_frame.shape} toll: {toll1} sx: {apertura_sx} dx: {apertura_dx}\")\n",
    "cv.imshow(\"unchanged\", uno)\n",
    "cv.imshow(\"cropped\", due)\n",
    "cv.imshow(\"crop_scaled\", tre)\n",
    "\n",
    "cv.waitKey(0) \n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ff83fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chin': [(118, 194), (117, 238), (120, 285), (132, 328), (157, 365), (193, 392), (232, 414), (271, 427), (308, 432), (340, 427), (364, 410), (383, 386), (395, 356), (406, 325), (414, 292), (416, 258), (412, 227)], 'left_eyebrow': [(169, 138), (197, 109), (235, 98), (276, 102), (311, 120)], 'right_eyebrow': [(348, 130), (375, 128), (399, 136), (415, 154), (416, 179)], 'nose_bridge': [(333, 163), (336, 182), (341, 201), (345, 221)], 'nose_tip': [(295, 258), (313, 262), (329, 264), (342, 266), (354, 265)], 'left_eye': [(219, 164), (241, 156), (262, 157), (279, 171), (261, 173), (239, 171)], 'right_eye': [(350, 189), (370, 184), (387, 190), (394, 205), (383, 205), (366, 198)], 'top_lip': [(249, 319), (282, 304), (309, 297), (324, 304), (342, 303), (356, 318), (363, 338), (355, 334), (340, 322), (322, 321), (306, 318), (261, 319)], 'bottom_lip': [(363, 338), (351, 344), (336, 350), (318, 350), (300, 346), (276, 333), (249, 319), (261, 319), (305, 320), (321, 324), (338, 324), (355, 334)]}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'res_frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11128/638330938.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_landmarks_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres_frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"crop_scaled\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtre\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'res_frame' is not defined"
     ]
    }
   ],
   "source": [
    "print(face_landmarks_list[0])\n",
    "tre = res_frame\n",
    "cv.imshow(\"crop_scaled\", tre)\n",
    "cv.waitKey(0) \n",
    "\n",
    "cv.destroyAllWindows()\n",
    "print(face_recognition.face_encodings(res_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48c352e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occhiolino False 0.3149797645528214 0.3325950526188697 -in: 0.0\n",
      "occhiolino True 0.36914789791412533 0.2949955097939174 -in: 0.0\n",
      "occhiolino False 0.3768510093300177 0.33586437448586365 -in: 0.0\n",
      "occhiolino False 0.3775863290718193 0.33357947635520163 -in: 0.0\n",
      "occhiolino False 0.38235294117647056 0.35233213170882205 -in: 0.0\n",
      "occhiolino True 0.27077018752058873 0.23529411764705882 -in: 0.0\n",
      "occhiolino True 0.2849881999516386 0.21832400154313186 -in: 0.0\n",
      "occhiolino True 0.30410352085392206 0.23529411764705882 -in: 0.0010001659393310547\n",
      "occhiolino True 0.36666666666666664 0.29651742278276144 -in: 0.0010013580322265625\n",
      "occhiolino True 0.34566186625242745 0.292103118918493 -in: 0.0\n",
      "occhiolino True 0.36666666666666664 0.2978879006693419 -in: 0.0\n",
      "occhiolino False 0.36666666666666664 0.3242058216857667 -in: 0.0\n",
      "occhiolino False 0.3775863290718193 0.303686696705828 -in: 0.0\n",
      "occhiolino True 0.34375 0.2949955097939174 -in: 0.0\n",
      "occhiolino True 0.3391817326856071 0.2693811516220012 -in: 0.0\n",
      "occhiolino True 0.2876301804462766 0.2139062186164015 -in: 0.0\n",
      "occhiolino True 0.2701704742980942 0.22766822768081374 -in: 0.0\n",
      "occhiolino True 0.21875 0.1875 -in: 0.0\n",
      "occhiolino True 0.3033006504530928 0.19444444444444445 -in: 0.0\n",
      "occhiolino True 0.3033006504530928 0.24211709905575113 -in: 0.001007080078125\n",
      "occhiolino True 0.3125 0.2693811516220012 -in: 0.0\n",
      "occhiolino True 0.375 0.29361010975735174 -in: 0.0\n",
      "occhiolino True 0.29361010975735174 0.2949955097939174 -in: 0.0\n",
      "occhiolino False 0.3235294117647059 0.3463363290718193 -in: 0.0\n",
      "occhiolino True 0.3258784337584966 0.29361010975735174 -in: 0.0\n",
      "occhiolino True 0.23488808780588138 0.3026288873903514 -in: 0.0\n",
      "occhiolino True 0.14705882352941177 0.16629752630943484 -in: 0.0\n",
      "occhiolino True 0.2 0.23281653683320877 -in: 0.0\n",
      "occhiolino True 0.23850259343081628 0.26666666666666666 -in: 0.0\n",
      "occhiolino True 0.2773500981126146 0.3794323017289523 -in: 0.0\n",
      "occhiolino True 0.2805283198220218 0.3155943597997745 -in: 0.0\n",
      "occhiolino True 0.1875 0.24936467495768377 -in: 0.0\n",
      "occhiolino True 0.1518316958873053 0.1875 -in: 0.0010008811950683594\n",
      "occhiolino True 0.26761822098802307 0.375 -in: 0.0\n",
      "occhiolino True 0.26279416561381835 0.35294117647058826 -in: 0.0\n",
      "occhiolino False 0.35294117647058826 0.35294117647058826 -in: 0.0\n",
      "occhiolino False 0.35294117647058826 0.35294117647058826 -in: 0.0010013580322265625\n",
      "occhiolino True 0.3553753685381829 0.29651742278276144 -in: 0.0\n",
      "occhiolino True 0.2805283198220218 0.31806809832974015 -in: 0.0\n",
      "occhiolino True 0.29411764705882354 0.29361010975735174 -in: 0.0\n",
      "occhiolino True 0.29411764705882354 0.29361010975735174 -in: 0.0\n",
      "occhiolino True 0.29411764705882354 0.29651742278276144 -in: 0.0\n",
      "occhiolino False 0.35294117647058826 0.31806809832974015 -in: 0.0\n",
      "occhiolino False 0.3553753685381829 0.3468443597997745 -in: 0.0\n",
      "occhiolino False 0.3333333333333333 0.3547621232692877 -in: 0.0\n",
      "occhiolino False 0.33563229250828386 0.38169314268455723 -in: 0.0\n",
      "occhiolino False 0.35294117647058826 0.3547621232692877 -in: 0.0009706020355224609\n",
      "occhiolino False 0.32297112073308687 0.3742697169310832 -in: 0.0\n",
      "occhiolino True 0.2805283198220218 0.29651742278276144 -in: 0.0\n",
      "occhiolino False 0.3055555555555556 0.35233213170882205 -in: 0.0\n",
      "occhiolino True 0.29411764705882354 0.24951314462072213 -in: 0.0\n",
      "occhiolino True 0.3055555555555556 0.29651742278276144 -in: 0.0\n",
      "occhiolino False 0.3235294117647059 0.3149797645528214 -in: 0.0\n",
      "occhiolino False 0.3333333333333333 0.3155943597997745 -in: 0.0\n",
      "occhiolino True 0.3055555555555556 0.29702998569390543 -in: 0.0\n",
      "occhiolino True 0.29411764705882354 0.3768510093300177 -in: 0.0\n",
      "occhiolino True 0.29411764705882354 0.28125 -in: 0.0\n",
      "occhiolino True 0.24951314462072213 0.25 -in: 0.0\n",
      "occhiolino True 0.19219615962682976 0.1752618713510958 -in: 0.0\n",
      "occhiolino True 0.22338530270442003 0.2055270768301462 -in: 0.0\n",
      "occhiolino True 0.25 0.23529411764705882 -in: 0.0\n",
      "occhiolino True 0.29361010975735174 0.31806809832974015 -in: 0.0\n",
      "occhiolino True 0.2845418466693579 0.3067233195933498 -in: 0.0\n",
      "occhiolino True 0.279078152825719 0.3149797645528214 -in: 0.0\n",
      "occhiolino True 0.20896918976428644 0.23631256084527205 -in: 0.0\n",
      "occhiolino True 0.2300894966542111 0.3247805496750857 -in: 0.0\n",
      "occhiolino False 0.30316953129541624 0.35355339059327373 -in: 0.0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\n",
    "# This is a demo of detecting eye status from the users camera. If the users eyes are closed for EYES_CLOSED seconds, the system will start printing out \"EYES CLOSED\"\n",
    "# to the terminal until the user presses and holds the spacebar to acknowledge\n",
    "\n",
    "# this demo must be run with sudo privileges for the keyboard module to work\n",
    "\n",
    "# PLEASE NOTE: This example requires OpenCV (the `cv2` library) to be installed only to read from your webcam.\n",
    "# OpenCV is *not* required to use the face_recognition library. It's only required if you want to run this\n",
    "# specific demo. If you have trouble installing it, try any of the other demos that don't require it instead.\n",
    "\n",
    "# imports\n",
    "import face_recognition\n",
    "import cv2\n",
    "import time\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "EYES_CLOSED_SECONDS = 5\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    framec = 0\n",
    "    closed_count = 0\n",
    "    video_capture = cv2.VideoCapture(\"Doorbell1.mp4\")\n",
    "\n",
    "    ret, frame = video_capture.read(0)\n",
    "    # cv2.VideoCapture.release()\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    face_landmarks_list = face_recognition.face_landmarks(rgb_small_frame)\n",
    "    process = True\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = video_capture.read(0)\n",
    "        \n",
    "        # get it into the correct format\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "        if process:\n",
    "            \n",
    "            face_landmarks_list = face_recognition.face_landmarks(rgb_small_frame)\n",
    "            #new_encoding = face_recognition.face_encodings(rgb_small_frame)[0]\n",
    "            #sblocco = face_recognition.compare_faces(known_face_encodings, new_encoding)\n",
    "            t0 = time.time()\n",
    "            # get eyes\n",
    "            for face_landmark in face_landmarks_list:\n",
    "                left_eye = face_landmark['left_eye']\n",
    "                right_eye = face_landmark['right_eye']\n",
    "                ear_left = get_ear(left_eye)\n",
    "                ear_right = get_ear(right_eye)\n",
    "                closed = ear_left < 0.3 or ear_right < 0.3\n",
    "                print(f\"occhiolino {closed} {ear_left} {ear_right} -in: {time.time()-t0}\")\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                #cv2.putText(small_frame, f'fps: {framec/(time.time()-t0)}', (100,10), font, 0.3, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(small_frame, f'Occhiolino: {closed}', (10,10), font, 0.3, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "                cv2.imshow('Video', small_frame)\n",
    "                framec += 1\n",
    "        process = not process\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def get_ear(eye):\n",
    "\t# compute the euclidean distances between the two sets of\n",
    "\t# vertical eye landmarks (x, y)-coordinates\n",
    "\tA = dist.euclidean(eye[1], eye[5])\n",
    "\tB = dist.euclidean(eye[2], eye[4])\n",
    " \n",
    "\t# compute the euclidean distance between the horizontal\n",
    "\t# eye landmark (x, y)-coordinates\n",
    "\tC = dist.euclidean(eye[0], eye[3])\n",
    " \n",
    "\t# compute the eye aspect ratio\n",
    "\tear = (A + B) / (2.0 * C)\n",
    " \n",
    "\t# return the eye aspect ratio\n",
    "\treturn ear\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bb490e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occhiolino False 7.0710678118654755 7.0710678118654755 -in: 0.0010006427764892578\n",
      "occhiolino True 10.04987562112089 9.055385138137417 -in: 0.0\n",
      "occhiolino False 9.055385138137417 9.055385138137417 -in: 0.0\n",
      "occhiolino False 10.04987562112089 10.0 -in: 0.0\n",
      "occhiolino True 11.0 10.0 -in: 0.0010297298431396484\n",
      "occhiolino False 8.06225774829855 8.06225774829855 -in: 0.0\n",
      "occhiolino False 13.038404810405298 13.0 -in: 0.0\n",
      "occhiolino True 10.04987562112089 9.0 -in: 0.0\n",
      "occhiolino False 18.0 18.110770276274835 -in: 0.0\n",
      "occhiolino False 18.027756377319946 18.110770276274835 -in: 0.0\n",
      "occhiolino False 18.027756377319946 18.110770276274835 -in: 0.0\n",
      "occhiolino False 18.027756377319946 18.027756377319946 -in: 0.0\n",
      "occhiolino True 13.0 12.0 -in: 0.0\n",
      "occhiolino True 14.035668847618199 15.033296378372908 -in: 0.0\n",
      "occhiolino True 13.038404810405298 14.035668847618199 -in: 0.0\n",
      "occhiolino True 13.0 14.035668847618199 -in: 0.0\n",
      "occhiolino True 13.038404810405298 12.0 -in: 0.0\n",
      "occhiolino True 12.0 14.035668847618199 -in: 0.0\n",
      "occhiolino True 12.0 13.0 -in: 0.0010006427764892578\n",
      "occhiolino True 12.0 13.0 -in: 0.0\n",
      "occhiolino False 12.0 12.0 -in: 0.0009999275207519531\n",
      "occhiolino False 12.0 12.0 -in: 0.0\n",
      "occhiolino True 11.0 12.041594578792296 -in: 0.0\n",
      "occhiolino True 13.0 14.035668847618199 -in: 0.0\n",
      "occhiolino True 7.0710678118654755 6.082762530298219 -in: 0.0\n",
      "occhiolino False 13.0 13.038404810405298 -in: 0.0\n",
      "occhiolino False 12.041594578792296 12.0 -in: 0.0\n",
      "occhiolino True 11.0 12.165525060596439 -in: 0.0\n",
      "occhiolino False 10.04987562112089 10.04987562112089 -in: 0.0\n",
      "occhiolino True 9.219544457292887 10.04987562112089 -in: 0.0009663105010986328\n",
      "occhiolino True 8.246211251235321 10.198039027185569 -in: 0.0\n",
      "occhiolino True 8.06225774829855 9.055385138137417 -in: 0.0009996891021728516\n",
      "occhiolino True 10.04987562112089 12.041594578792296 -in: 0.0010013580322265625\n",
      "occhiolino True 10.04987562112089 12.041594578792296 -in: 0.0\n",
      "occhiolino True 10.04987562112089 12.041594578792296 -in: 0.0\n",
      "occhiolino True 11.045361017187261 12.165525060596439 -in: 0.0\n",
      "occhiolino True 10.04987562112089 11.045361017187261 -in: 0.0\n",
      "occhiolino True 10.04987562112089 9.0 -in: 0.0\n",
      "occhiolino True 7.211102550927978 5.830951894845301 -in: 0.0\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "5.830951894845301\n",
      "7.211102550927978\n",
      "True\n",
      "2\n",
      "0.9852454662322998\n"
     ]
    }
   ],
   "source": [
    "# sorriso e occhiolino con scaling funzionante\n",
    "\n",
    "import face_recognition\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "from scipy.spatial import distance as dist\n",
    "import time\n",
    "\n",
    "def main():\n",
    "    framec = 0;\n",
    "    path = \"photos/leo.jpg\"\n",
    "    cattura = 0\n",
    "    # \"myvideo.mp4\" \"Doorbell2.mp4\"  \"occhiolino.mp4\" \"Doorbell1.mp4\" \"leo_wink_smile.mp4\" \"Doorbell1.mp4\"\n",
    "    imagel = face_recognition.load_image_file(path)\n",
    "    imagea = face_recognition.load_image_file(\"photos/ma.png\")\n",
    "    try:\n",
    "        leo_face_encoding = face_recognition.face_encodings(imagel)[0]\n",
    "        ma_face_encoding = face_recognition.face_encodings(imagea)[0]\n",
    "    except Error:\n",
    "        print(\"I didn't any faces, quitting...\\n\")\n",
    "        time.sleep(0.02)\n",
    "        print(\".\\n\")\n",
    "        time.sleep(0.02)\n",
    "        print(\".\\n\")\n",
    "        time.sleep(0.02)\n",
    "        print(\".\\n\")\n",
    "\n",
    "    known_face_encodings = [\n",
    "        leo_face_encoding,\n",
    "        ma_face_encoding\n",
    "    ]\n",
    "    cap = cv.VideoCapture(cattura)\n",
    "    ret, frame = cap.read(0)\n",
    "    apertura_sx = 0\n",
    "    apertura_dx = 0\n",
    "    toll1 = 2\n",
    "    sblocco = [False]\n",
    "    sorriso = False\n",
    "    occhiolino = False\n",
    "    cfs = 0\n",
    "    cfo = 0\n",
    "    arr = Image.fromarray(frame)\n",
    "    if arr.size[0] < 500 and arr.size[1] < 300:\n",
    "        print(\"qualità troppo bassa impossibile misurare correttamente\")\n",
    "        exit()\n",
    "    t0 = time.time()\n",
    "    while(True):\n",
    "        ret, frame = cap.read(0)    \n",
    "        res_frame = cv.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        face_locations = face_recognition.face_locations(res_frame)\n",
    "        face_encodings = face_recognition.face_encodings(res_frame, face_locations)\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        if framec % 5 == 0:\n",
    "            for face_encoding in face_encodings:\n",
    "                sblocco = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "        if framec % 2 == 0:\n",
    "            face_landmarks_list = face_recognition.face_landmarks(res_frame)\n",
    "            t0 = time.time()\n",
    "            for face_landmark in face_landmarks_list:\n",
    "                occhiosx = face_landmark[\"left_eye\"]\n",
    "                occhiodx = face_landmark[\"right_eye\"]\n",
    "                apertura_sx = get_op(occhiosx)\n",
    "                apertura_dx = get_op(occhiodx)\n",
    "                occhiolino = (apertura_sx < (apertura_dx-0.8) or apertura_dx < (apertura_sx-0.8)) and sblocco[0]\n",
    "                print(f\"occhiolino {occhiolino} {apertura_sx} {apertura_dx} -in: {time.time()-t0}\")\n",
    "            \n",
    "        if cv.waitKey(1) & 0xFF == ord('q') or (sblocco and occhiolino and sorriso):\n",
    "            break\n",
    "        framec += 1\n",
    "        font = cv.FONT_HERSHEY_SIMPLEX\n",
    "        cv.putText(res_frame, f'f{sblocco} w{occhiolino} s{sorriso}', (10,10), font, 0.3, (0, 255, 0), 1, cv.LINE_AA)\n",
    "        res_frame = cv.resize(res_frame, (600, 800))\n",
    "        cv.imshow(\"frame\", res_frame)\n",
    "\n",
    "\n",
    "    # Destroy all the windows\n",
    "    time.sleep(0.2)\n",
    "    print(\".\\n\")\n",
    "    time.sleep(0.2)\n",
    "    print(\".\\n\")\n",
    "    time.sleep(0.2)\n",
    "    print(\".\\n\")\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    print(apertura_dx)\n",
    "    print(apertura_sx)\n",
    "    print(occhiolino)\n",
    "    print(toll1)\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    print(total)\n",
    "    \n",
    "def get_op(eye):\n",
    "    return dist.euclidean(eye[4], eye[2])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a259e9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "0\n",
      "0\n",
      "False\n",
      "2\n",
      "fps: 0.8752019141035514\n"
     ]
    }
   ],
   "source": [
    "# e occhiolino con scaling funzionante\n",
    "\n",
    "import face_recognition\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "from scipy.spatial import distance as dist\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def main():\n",
    "    framec = 0;\n",
    "    path = \"photos/leo.jpg\"\n",
    "    cattura = 1\n",
    "    # \"myvideo.mp4\" \"Doorbell2.mp4\"  \"occhiolino.mp4\"   \"Doorbell1.mp4\"\"Doorbell1.mp4\" \"leo_wink_smile.mp4\"\n",
    "    imagel = face_recognition.load_image_file(path)\n",
    "    imagea = face_recognition.load_image_file(\"photos/ma.png\")\n",
    "    try:\n",
    "        leo_face_encoding = face_recognition.face_encodings(imagel)[0]\n",
    "        ma_face_encoding = face_recognition.face_encodings(imagea)[0]\n",
    "    except Error:\n",
    "        print(\"I didn't any faces, quitting...\\n\")\n",
    "        time.sleep(0.02)\n",
    "        print(\".\\n\")\n",
    "        time.sleep(0.02)\n",
    "        print(\".\\n\")\n",
    "        time.sleep(0.02)\n",
    "        print(\".\\n\")\n",
    "\n",
    "    known_face_encodings = [\n",
    "        leo_face_encoding,\n",
    "        ma_face_encoding\n",
    "    ]\n",
    "    \n",
    "    known_face_names = [\n",
    "        \"leo\",\n",
    "        \"maurizio\"\n",
    "    ]\n",
    "    face_names = []\n",
    "    cap = cv.VideoCapture(cattura)\n",
    "    ret, frame = cap.read(0)\n",
    "    apertura_sx = 0\n",
    "    apertura_dx = 0\n",
    "    toll1 = 2\n",
    "    matches = [False]\n",
    "    sorriso = False\n",
    "    occhiolino = False\n",
    "    name = \"Unknown\"\n",
    "    cfs = 0\n",
    "    cfo = 0\n",
    "    arr = Image.fromarray(frame)\n",
    "    if arr.size[0] < 500 and arr.size[1] < 300:\n",
    "        print(\"qualità troppo bassa impossibile misurare correttamente\")\n",
    "        exit()\n",
    "    t0 = time.time()\n",
    "    while(True):\n",
    "        ret, frame = cap.read(0)  \n",
    "        if not ret:\n",
    "            break\n",
    "        res_frame = cv.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        face_locations = face_recognition.face_locations(res_frame)    \n",
    "        if framec % 20 == 0:\n",
    "            face_encodings = face_recognition.face_encodings(res_frame, face_locations)\n",
    "            for face_encoding in face_encodings:\n",
    "                matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                name = \"Unknown\"\n",
    "                face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "                face_names.append(name)\n",
    "                if True in matches:\n",
    "                    first_match_index = matches.index(True)\n",
    "                    name = known_face_names[first_match_index]\n",
    "                \n",
    "        if framec % 3 == 0:\n",
    "            face_landmarks_list = face_recognition.face_landmarks(res_frame) \n",
    "            for face_landmark in face_landmarks_list:\n",
    "                occhiosx = face_landmark[\"left_eye\"]\n",
    "                occhiodx = face_landmark[\"right_eye\"]\n",
    "                apertura_sx = get_ear(occhiosx)\n",
    "                apertura_dx = get_ear(occhiodx)\n",
    "                occhiolino = ((not (apertura_sx < 0.25) and (apertura_dx < 0.25)) or\n",
    "                    (not (apertura_dx < 0.25) and (apertura_sx < 0.25)) and True in matches)\n",
    "                toplip = face_landmark[\"top_lip\"]\n",
    "                bottomlip = face_landmark[\"bottom_lip\"]\n",
    "                smiletl = get_smile_tl(toplip)\n",
    "                smileop = get_smile_op(toplip, bottomlip)\n",
    "                sorriso = smiletl or smileop\n",
    "                print(f\"\\nsblocco{True in matches}\\nocchiolino {occhiolino} {apertura_sx} {apertura_dx} \\nsorriso {sorriso} {smileop} {smiletl} \\ntempo: {time.time()-t0}\")\n",
    "        framec += 1\n",
    "        font = cv.FONT_HERSHEY_SIMPLEX\n",
    "        for (top, right, bottom, left) in face_locations:\n",
    "            cv.rectangle(res_frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "            # Draw a label with a name below the face\n",
    "            cv.rectangle(res_frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv.FILLED)\n",
    "            cv.putText(res_frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "        cv.putText(res_frame, f'f{matches} w{occhiolino} s{sorriso}', (10,10), font, 0.2, (0, 0, 0), 1, cv.LINE_AA)\n",
    "        res_frame = cv.resize(res_frame, (600, 800))\n",
    "        cv.imshow(\"frame\", res_frame)\n",
    "        \n",
    "        if cv.waitKey(1) & 0xFF == ord('q') : # or (True in matches and occhiolino and sorriso):\n",
    "            break\n",
    "\n",
    "    # Destroy all the windows\n",
    "    time.sleep(0.2)\n",
    "    print(\".\\n\")\n",
    "    time.sleep(0.2)\n",
    "    print(\".\\n\")\n",
    "    time.sleep(0.2)\n",
    "    print(\".\\n\")\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    print(apertura_dx)\n",
    "    print(apertura_sx)\n",
    "    print(occhiolino)\n",
    "    print(toll1)\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    print(f\"fps: {framec/total}\")\n",
    "    \n",
    "def get_ear(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def get_smile_tl(top_lip):\n",
    "    return top_lip[0][1]<top_lip[4][1] or top_lip[6][1]<top_lip[2][1]\n",
    "\n",
    "def get_smile_op(top_lip, bottom_lip):\n",
    "    sar = dist.euclidean(top_lip[0],top_lip[6])/dist.euclidean(bottom_lip[9],top_lip[9])\n",
    "    return sar < 5 and sar > 3\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f209c81",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-c2l3r8zm\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7288/4217976789.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#cv.putText(res_frame, f'fps: {framec/(time.time()-t0)}', (100,10), font, 0.3, (0, 255, 0), 1, cv.LINE_AA)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7288/4217976789.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mres_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mface_locations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mface_locations\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-c2l3r8zm\\opencv\\modules\\imgproc\\src\\resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2 as cv\n",
    "import time\n",
    "def main():\n",
    "    t0 = time.time()\n",
    "    framec = 0\n",
    "    cattura = \"doc.mp4\"\n",
    "    cap = cv.VideoCapture(cattura)\n",
    "    while(True):\n",
    "        ret, frame = cap.read(0)    \n",
    "        if not ret: break\n",
    "        res_frame = cv.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        face_locations = face_recognition.face_locations(res_frame)\n",
    "        if face_locations:\n",
    "            top, right, bottom, left = face_locations[0]\n",
    "            cv.rectangle(res_frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        font = cv.FONT_HERSHEY_SIMPLEX\n",
    "        cv.imshow(\"frame\", res_frame)\n",
    "        framec +=1\n",
    "    print(f'fps: {framec/(time.time()-t0)}')  \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "   \n",
    "#cv.putText(res_frame, f'fps: {framec/(time.time()-t0)}', (100,10), font, 0.3, (0, 255, 0), 1, cv.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec478428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n",
      "persona!\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2 as cv\n",
    "import time\n",
    "def main():\n",
    "    t0 = time.time()\n",
    "    framec = 0\n",
    "    cattura = 1\n",
    "    cap = cv.VideoCapture(cattura)\n",
    "    while(True):\n",
    "        ret, frame = cap.read(0)    \n",
    "        #res_frame = frame\n",
    "        res_frame = cv.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        face_locations = face_recognition.face_locations(res_frame)\n",
    "        if face_locations:\n",
    "            print(\"persona!\")\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        font = cv.FONT_HERSHEY_SIMPLEX\n",
    "        if ret: cv.imshow(\"frame\", res_frame)\n",
    "        framec +=1\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1da3deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "avg fps: 3.3959527903862954\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2 as cv\n",
    "import time\n",
    "def main():\n",
    "    t0 = time.time()\n",
    "    framec = 0\n",
    "    cattura = \"test.MOV\"\n",
    "    cap = cv.VideoCapture(cattura)\n",
    "    while(True):\n",
    "        ret, frame = cap.read(0)    \n",
    "        if not ret : break\n",
    "        #res_frame = frame\n",
    "        res_frame = cv.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        face_locations = face_recognition.face_locations(res_frame)\n",
    "        print(len(face_locations))\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        font = cv.FONT_HERSHEY_SIMPLEX\n",
    "        cv.putText(res_frame, f'fps: {framec/(time.time()-t0)}', (100,10), font, 0.3, (0, 255, 0), 1, cv.LINE_AA)\n",
    "        if ret: cv.imshow(\"frame\", res_frame)\n",
    "        framec +=1\n",
    "        \n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    print(f\"avg fps: {framec/(time.time()-t0)}\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df6815ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps: 3.08401540511781\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "from scipy.spatial import distance as dist\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    framec = 0\n",
    "    cattura =\"joe_and_meg.mp4\"\n",
    "    imageb = face_recognition.load_image_file(\"photos/biden.jpeg\")\n",
    "    imagem = face_recognition.load_image_file(\"photos/megan.jpg\")\n",
    "    try:\n",
    "        bi_face_encoding = face_recognition.face_encodings(imageb)[0]\n",
    "        meg_face_encoding = face_recognition.face_encodings(imagem)[0]\n",
    "    except:\n",
    "        print(\"I didn't any faces, quitting...\\n\")\n",
    "        sys.exit()\n",
    "    known_face_encodings = [bi_face_encoding, meg_face_encoding]\n",
    "    known_face_names = [\"Joe\", \"Meg\"]\n",
    "    cap = cv.VideoCapture(cattura)\n",
    "    face_names = []\n",
    "    sblocco = [False]\n",
    "    t0 = time.time()\n",
    "    font = cv.FONT_HERSHEY_SIMPLEX\n",
    "    while(True):\n",
    "        ret, frame = cap.read(0)  \n",
    "        if not ret:\n",
    "            break\n",
    "        res_frame = cv.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        face_locations = face_recognition.face_locations(res_frame)    \n",
    "        if framec % 15 == 0:\n",
    "            face_encodings = face_recognition.face_encodings(res_frame, face_locations)\n",
    "            face_names = []\n",
    "            for face_encoding in face_encodings:\n",
    "                matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                name = \"Unknown\"\n",
    "                face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "                face_names.append(name)\n",
    "                if True in matches:\n",
    "                    first_match_index = matches.index(True)\n",
    "                    name = known_face_names[first_match_index]\n",
    "        for (top, right, bottom, left),name in zip(face_locations, face_names):\n",
    "            cv.rectangle(res_frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "            cv.rectangle(res_frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv.FILLED)\n",
    "            cv.putText(res_frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "        framec += 1\n",
    "        \n",
    "        cv.imshow(\"frame\", res_frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "    t1 = time.time()\n",
    "    total = framec/(t1-t0)\n",
    "    print(f\"fps: {total}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11d7fdf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5336/2828260377.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mframec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"fps: {total}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't1' is not defined"
     ]
    }
   ],
   "source": [
    "total = (t1-t0)/framec\n",
    "print(f\"fps: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f10efee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errore\n",
      "errore ap sx0.1452223967283886 ap dx0.15594571538795132\n",
      "smile at:          0.4880518913269043\n",
      "test concluded in: 0.4880518913269043\n",
      "image dimensions:  (236, 355, 3)\n"
     ]
    }
   ],
   "source": [
    "# test velocità riconoscimento facciale e features\n",
    "import face_recognition\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import time\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "def main():\n",
    "    imagel = face_recognition.load_image_file(\"photos/leo.jpg\")\n",
    "    imageb = face_recognition.load_image_file(\"photos/biden.jpeg\")\n",
    "    imagea = face_recognition.load_image_file(\"photos/ma.png\")\n",
    "    try:\n",
    "        leo_face_encoding = face_recognition.face_encodings(imagel)[0]\n",
    "        bi_face_encoding = face_recognition.face_encodings(imageb)[0]\n",
    "        ma_face_encoding = face_recognition.face_encodings(imagea)[0]\n",
    "    except Error:\n",
    "        print(\"I didn't any faces, quitting...\\n\")\n",
    "        time.sleep(0.02)\n",
    "        print(\".\\n\")\n",
    "        time.sleep(0.02)\n",
    "        print(\".\\n\")\n",
    "        time.sleep(0.02)\n",
    "        print(\".\\n\")\n",
    "\n",
    "    known_face_encodings = [\n",
    "        leo_face_encoding,\n",
    "        bi_face_encoding,\n",
    "        ma_face_encoding\n",
    "    ]\n",
    "    occhiolino = False\n",
    "    sorriso = False\n",
    "    sblocco = [False]\n",
    "    t_start = 0\n",
    "    t_sblocco = 0\n",
    "    t_occhiolino = 0\n",
    "    t_sorriso = 0\n",
    "    img = cv.imread('photos/maur_wink_smile.png', cv.IMREAD_UNCHANGED)\n",
    "    toll1 = 19 # euristico\n",
    "    uno = img\n",
    "\n",
    "    t_start = time.time()\n",
    "    image = cv.imread(\"photos/wink3.jpg\")\n",
    "    image = cv.resize(image, (0, 0), fx=0.5, fy=0.5)\n",
    "    new_encoding = face_recognition.face_encodings(image)[0]\n",
    "    sblocco = face_recognition.compare_faces(known_face_encodings, new_encoding)\n",
    "    if True in sblocco: t_sblocco = time.time()\n",
    "    face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "    for face_landmark in face_landmarks_list:\n",
    "        occhiosx = face_landmark[\"left_eye\"]\n",
    "        occhiodx = face_landmark[\"right_eye\"]\n",
    "        apertura_sx = get_ear(occhiosx)\n",
    "        apertura_dx = get_ear(occhiodx)\n",
    "        occhiolino = (not (apertura_sx < 0.23) and (apertura_dx < 0.23)) or (not (apertura_dx < 0.23) and (apertura_sx < 0.23))\n",
    "        if occhiolino: t_occhiolino = time.time()\n",
    "        toplip = face_landmark[\"top_lip\"]\n",
    "        bottomlip = face_landmark[\"bottom_lip\"]\n",
    "        smiletl = get_smile_tl(toplip)\n",
    "        smileop = get_smile_op(toplip, bottomlip)\n",
    "        sorriso = smiletl or smileop\n",
    "        if sorriso: t_sorriso = time.time()\n",
    "        t_end = time.time()\n",
    "    \n",
    "    if True in sblocco: print(f\"unlocked at:       {t_sblocco - t_start}\") \n",
    "    else: print(\"errore\")\n",
    "    if occhiolino: print(f\"wink at:           {t_occhiolino - t_start} ap sx{apertura_sx} ap dx{apertura_dx}\") \n",
    "    else: print(f\"errore ap sx{apertura_sx} ap dx{apertura_dx}\") \n",
    "    if sorriso: print(f\"smile at:          {t_sorriso - t_start}\") \n",
    "    else: print(\"errore\")\n",
    "    print(f\"test concluded in: {t_end - t_start}\")\n",
    "    print(f\"image dimensions:  {image.shape}\")\n",
    "    cv.imshow(\"cframe\", image)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows() \n",
    "\n",
    "def get_ear(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    # compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    # return the eye aspect ratio\n",
    "    return ear\n",
    "\n",
    "    \n",
    "def get_smile_tl(top_lip):\n",
    "    return top_lip[0][1]<top_lip[4][1] or top_lip[6][1]<top_lip[2][1] or top_lip[0][1]<top_lip[6][1] or top_lip[6][1]<top_lip[0][1]\n",
    "\n",
    "def get_smile_op(top_lip, bottom_lip):\n",
    "    sar = dist.euclidean(top_lip[0],top_lip[6])/dist.euclidean(bottom_lip[9],top_lip[9])\n",
    "    return sar < 5.5 and sar > 3\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
